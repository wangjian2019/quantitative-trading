#!/usr/bin/env python3
"""
æµ‹è¯• TinyTransformer æ¨¡å‹
ä½¿ç”¨æ­£ç¡®çš„æ¨¡å‹æ¶æ„åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹

ä½œè€…: Alvin
"""

import torch
import torch.nn as nn
import pickle
import yfinance as yf
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import json
import warnings
warnings.filterwarnings("ignore")

# å¤åˆ¶TinyTransformeræ¶æ„å®šä¹‰
class TinyTransformer(nn.Module):
    def __init__(self, input_dim=21, d_model=64, nhead=8, num_layers=2, num_classes=3, seq_len=30):
        super().__init__()

        self.input_projection = nn.Linear(input_dim, d_model)
        self.pos_encoding = nn.Parameter(torch.randn(seq_len, d_model))

        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=d_model * 2,
            dropout=0.1,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)

        self.classifier = nn.Sequential(
            nn.Linear(d_model, d_model // 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(d_model // 2, num_classes)
        )

    def forward(self, x):
        seq_len = x.size(1)

        # æŠ•å½±åˆ°æ¨¡å‹ç»´åº¦
        x = self.input_projection(x)

        # æ·»åŠ ä½ç½®ç¼–ç 
        pos_len = min(seq_len, self.pos_encoding.size(0))
        x[:, :pos_len, :] = x[:, :pos_len, :] + self.pos_encoding[:pos_len].unsqueeze(0)

        # Transformerç¼–ç 
        x = self.transformer(x)

        # ä½¿ç”¨æœ€åä¸€ä¸ªæ—¶é—´æ­¥
        x = x[:, -1, :]

        # åˆ†ç±»
        output = self.classifier(x)

        return output

def calculate_basic_features(df):
    """è®¡ç®—åŸºç¡€ç‰¹å¾ - ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´"""
    features = []

    # ä»·æ ¼ç›¸å…³ç‰¹å¾
    close = df['Close'].values
    volume = df['Volume'].values

    for i in range(len(df)):
        feature_row = []

        # åŸºç¡€ä»·æ ¼ç‰¹å¾
        current_close = close[i]
        feature_row.extend([
            df['Open'].iloc[i] / current_close,
            df['High'].iloc[i] / current_close,
            df['Low'].iloc[i] / current_close,
            1.0,  # close / close = 1
            df['Volume'].iloc[i] / 1e6  # æ ‡å‡†åŒ–æˆäº¤é‡
        ])

        # å†å²ç‰¹å¾ï¼ˆå¦‚æœæœ‰è¶³å¤Ÿå†å²æ•°æ®ï¼‰
        if i > 0:
            prev_close = close[i-1]
            feature_row.extend([
                (current_close - prev_close) / prev_close,  # æ—¥æ”¶ç›Šç‡
            ])
        else:
            feature_row.extend([0.0])

        # ç§»åŠ¨å¹³å‡ç‰¹å¾
        if i >= 4:
            ma5 = np.mean(close[max(0, i-4):i+1])
            feature_row.extend([current_close / ma5 - 1])
        else:
            feature_row.extend([0.0])

        if i >= 9:
            ma10 = np.mean(close[max(0, i-9):i+1])
            feature_row.extend([current_close / ma10 - 1])
        else:
            feature_row.extend([0.0])

        # æ³¢åŠ¨ç‡ç‰¹å¾
        if i >= 9:
            recent_prices = close[max(0, i-9):i+1]
            volatility = np.std(recent_prices) / np.mean(recent_prices)
            feature_row.extend([volatility])
        else:
            feature_row.extend([0.02])

        # RSIç‰¹å¾ï¼ˆç®€åŒ–ç‰ˆï¼‰
        if i >= 13:
            gains = []
            losses = []
            for j in range(max(0, i-13), i):
                change = close[j+1] - close[j]
                if change > 0:
                    gains.append(change)
                    losses.append(0)
                else:
                    gains.append(0)
                    losses.append(-change)

            avg_gain = np.mean(gains)
            avg_loss = np.mean(losses)
            rs = avg_gain / (avg_loss + 1e-6)
            rsi = 100 - (100 / (1 + rs))
            feature_row.extend([rsi / 100.0])
        else:
            feature_row.extend([0.5])

        # æˆäº¤é‡æ¯”ç‡
        if i >= 19:
            vol_ma20 = np.mean(volume[max(0, i-19):i+1])
            vol_ratio = volume[i] / (vol_ma20 + 1e-6)
            feature_row.extend([min(vol_ratio, 5.0)])
        else:
            feature_row.extend([1.0])

        # å¡«å……åˆ°21ä¸ªç‰¹å¾
        while len(feature_row) < 21:
            feature_row.append(0.0)

        features.append(feature_row[:21])

    return np.array(features)

class TinyModelTester:
    def __init__(self):
        self.device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')
        self.model = None
        self.scaler = None
        self.model_info = None
        self.load_model()

    def load_model(self):
        """åŠ è½½TinyTransformeræ¨¡å‹"""
        try:
            # åŠ è½½æ¨¡å‹ä¿¡æ¯
            with open('tiny_model_info.pkl', 'rb') as f:
                self.model_info = pickle.load(f)
            print(f"âœ… æ¨¡å‹ä¿¡æ¯: {self.model_info}")

            # åŠ è½½ç¼©æ”¾å™¨
            with open('tiny_scaler.pkl', 'rb') as f:
                self.scaler = pickle.load(f)
            print("âœ… ç¼©æ”¾å™¨åŠ è½½æˆåŠŸ")

            # åˆ›å»ºæ­£ç¡®çš„æ¨¡å‹å®ä¾‹
            self.model = TinyTransformer(
                input_dim=21,
                d_model=64,  # è®­ç»ƒæ—¶ä½¿ç”¨çš„å‚æ•°
                nhead=8,
                num_layers=2,
                num_classes=3,
                seq_len=30
            ).to(self.device)

            # åŠ è½½æ¨¡å‹æƒé‡
            checkpoint = torch.load('tiny_transformer_model.pth', map_location=self.device)
            self.model.load_state_dict(checkpoint)
            self.model.eval()
            print("âœ… TinyTransformeræ¨¡å‹åŠ è½½æˆåŠŸ!")
            print(f"ğŸ“Š æ¨¡å‹å‡†ç¡®ç‡: {self.model_info.get('accuracy', 'Unknown'):.2%}")

        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

    def predict_signal(self, symbol):
        """é¢„æµ‹äº¤æ˜“ä¿¡å·"""
        if self.model is None:
            return None

        try:
            # è·å–å†å²æ•°æ®
            end_date = datetime.now()
            start_date = end_date - timedelta(days=100)

            ticker = yf.Ticker(symbol)
            hist = ticker.history(start=start_date, end=end_date)

            if len(hist) < 50:
                print(f"âŒ {symbol} å†å²æ•°æ®ä¸è¶³")
                return None

            # è®¡ç®—ç‰¹å¾
            features = calculate_basic_features(hist)

            if len(features) < 30:
                print(f"âŒ {symbol} ç‰¹å¾æ•°æ®ä¸è¶³")
                return None

            # å–æœ€å30å¤©çš„æ•°æ®
            recent_features = features[-30:]

            # æ ‡å‡†åŒ–ç‰¹å¾
            feature_shape = recent_features.shape
            recent_features = recent_features.reshape(-1, feature_shape[-1])
            recent_features = self.scaler.transform(recent_features)
            recent_features = recent_features.reshape(1, 30, -1)

            # è½¬æ¢ä¸ºå¼ é‡
            X = torch.FloatTensor(recent_features).to(self.device)

            # æ¨¡å‹é¢„æµ‹
            with torch.no_grad():
                logits = self.model(X)
                probabilities = torch.softmax(logits, dim=1)

                predicted_class = torch.argmax(probabilities, dim=1).item()
                confidence = torch.max(probabilities).item()

            # è½¬æ¢ä¸ºäº¤æ˜“åŠ¨ä½œ
            actions = ["SELL", "HOLD", "BUY"]
            action = actions[predicted_class]

            current_price = hist['Close'].iloc[-1]

            signal = {
                'symbol': symbol,
                'action': action,
                'confidence': confidence,
                'current_price': float(current_price),
                'predicted_class': predicted_class,
                'timestamp': datetime.now().isoformat(),
                'model_type': 'TinyTransformer',
                'model_accuracy': self.model_info.get('accuracy', 0.746)
            }

            print(f"ğŸ¯ {symbol}: {action} (ç½®ä¿¡åº¦: {confidence:.2%}, ç±»åˆ«: {predicted_class})")
            return signal

        except Exception as e:
            print(f"âŒ {symbol} é¢„æµ‹å¤±è´¥: {e}")
            return None

    def test_multiple_stocks(self, symbols):
        """æµ‹è¯•å¤šä¸ªè‚¡ç¥¨"""
        print("ğŸš€ å¼€å§‹TinyTransformeræ¨¡å‹æµ‹è¯•...")
        print("="*60)

        results = {}

        for symbol in symbols:
            signal = self.predict_signal(symbol)
            if signal:
                results[symbol] = signal

        # ä¿å­˜ç»“æœ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"tiny_model_results_{timestamp}.json"

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {filename}")

        # ç»Ÿè®¡ç»“æœ
        if results:
            print("\nğŸ“Š é¢„æµ‹ç»“æœæ±‡æ€»:")
            print("="*60)
            print(f"{'è‚¡ç¥¨':<8s} | {'åŠ¨ä½œ':<4s} | {'ç½®ä¿¡åº¦':<8s} | {'å½“å‰ä»·æ ¼':<10s}")
            print("-" * 40)

            action_counts = {"BUY": 0, "HOLD": 0, "SELL": 0}
            total_confidence = 0

            for symbol, result in results.items():
                print(f"{symbol:<8s} | {result['action']:<4s} | {result['confidence']:<8.2%} | ${result['current_price']:<9.2f}")
                action_counts[result['action']] += 1
                total_confidence += result['confidence']

            print("-" * 40)
            print(f"ğŸ“ˆ BUY: {action_counts['BUY']} | ğŸ“Š HOLD: {action_counts['HOLD']} | ğŸ“‰ SELL: {action_counts['SELL']}")
            print(f"ğŸ¯ å¹³å‡ç½®ä¿¡åº¦: {total_confidence/len(results):.2%}")
            print(f"âœ… æˆåŠŸæµ‹è¯• {len(results)} åªè‚¡ç¥¨")

        return results

def main():
    tester = TinyModelTester()

    if tester.model is None:
        print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥")
        return

    # æµ‹è¯•è®­ç»ƒé›†ä¸­çš„è‚¡ç¥¨
    train_symbols = ['AAPL', 'TSLA', 'MSFT', 'GOOGL', 'QQQ', 'NVDA', 'AMZN', 'META']

    print("ğŸ§ª æµ‹è¯•è®­ç»ƒé›†è‚¡ç¥¨...")
    train_results = tester.test_multiple_stocks(train_symbols)

    print("\n" + "="*60)
    print("ğŸ†• æµ‹è¯•è®­ç»ƒé›†å¤–è‚¡ç¥¨...")

    # æµ‹è¯•ä¸€äº›è®­ç»ƒé›†å¤–çš„è‚¡ç¥¨
    test_symbols = ['UBER', 'SHOP', 'NFLX', 'AMD']
    test_results = tester.test_multiple_stocks(test_symbols)

    print(f"\nğŸ‰ æµ‹è¯•å®Œæˆ! å…±æµ‹è¯•äº† {len(train_results) + len(test_results)} åªè‚¡ç¥¨")

if __name__ == "__main__":
    main()