#!/usr/bin/env python3
"""
é‡æ–°è®­ç»ƒAIæ¨¡å‹ä»¥æ”¯æŒ80ä¸ªç‰¹å¾
Author: Alvin
"""

import sys
import os
import json
import numpy as np
from datetime import datetime, timedelta
from ai_model_service import ai_model

def generate_training_data(num_samples=1000):
    """ç”Ÿæˆæ¨¡æ‹Ÿè®­ç»ƒæ•°æ®ä»¥é‡æ–°è®­ç»ƒæ¨¡å‹"""
    print(f"ğŸ”„ ç”Ÿæˆ{num_samples}ä¸ªè®­ç»ƒæ ·æœ¬...")
    
    training_data = []
    base_price = 100.0
    
    for i in range(num_samples):
        # æ¨¡æ‹Ÿä»·æ ¼èµ°åŠ¿
        trend = 0.001 if i < num_samples // 2 else -0.0005
        noise = np.random.normal(0, 0.02)
        price_change = trend + noise
        base_price *= (1 + price_change)
        
        # ç”ŸæˆOHLCVæ•°æ®
        open_price = base_price
        high_price = base_price * (1 + abs(np.random.normal(0, 0.01)))
        low_price = base_price * (1 - abs(np.random.normal(0, 0.01)))
        close_price = base_price
        volume = int(np.random.normal(10000, 3000))
        
        sample = {
            'timestamp': (datetime.now() - timedelta(days=num_samples-i)).isoformat(),
            'open': round(open_price, 2),
            'high': round(high_price, 2),
            'low': round(low_price, 2),
            'close': round(close_price, 2),
            'volume': max(volume, 1000)
        }
        training_data.append(sample)
    
    return training_data

def retrain_models():
    """é‡æ–°è®­ç»ƒæ¨¡å‹ä»¥æ”¯æŒ80ä¸ªç‰¹å¾"""
    print("ğŸš€ å¼€å§‹é‡æ–°è®­ç»ƒAIæ¨¡å‹...")
    print("ç›®æ ‡: æ”¯æŒ80ä¸ªç‰¹å¾ï¼Œæå‡æ”¶ç›Šç‡")
    print("="*60)
    
    # ç”Ÿæˆè®­ç»ƒæ•°æ®
    training_data = generate_training_data(2000)  # å¢åŠ è®­ç»ƒæ•°æ®
    
    # å¤‡ä»½åŸæœ‰æ¨¡å‹
    print("ğŸ“¦ å¤‡ä»½åŸæœ‰æ¨¡å‹...")
    import shutil
    import glob
    
    backup_dir = f"models_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    os.makedirs(backup_dir, exist_ok=True)
    
    for file in glob.glob("models/*.pkl") + glob.glob("models/*.json"):
        shutil.copy2(file, backup_dir)
    print(f"âœ… æ¨¡å‹å·²å¤‡ä»½åˆ°: {backup_dir}")
    
    # é‡æ–°è®­ç»ƒ
    print("ğŸ¤– å¼€å§‹è®­ç»ƒæ–°æ¨¡å‹...")
    success = ai_model.train_models(training_data)
    
    if success:
        print("âœ… æ¨¡å‹é‡æ–°è®­ç»ƒæˆåŠŸ!")
        print(f"âœ… æ–°ç‰¹å¾æ•°é‡: {len(ai_model.feature_columns)}")
        print(f"âœ… æ¨¡å‹æ€§èƒ½: {ai_model.model_performance}")
        
        # æµ‹è¯•æ–°æ¨¡å‹
        print("\nğŸ§ª æµ‹è¯•æ–°æ¨¡å‹...")
        test_signal = ai_model.generate_signal(
            {'close': 100, 'volume': 1000000},
            {'RSI': 25, 'MACD': 1.5, 'MA5': 100, 'MA20': 98, 'VOLATILITY': 0.03, 'VOLUME_RATIO': 2.5},
            []
        )
        print(f"æµ‹è¯•ä¿¡å·: {test_signal['action']} ç½®ä¿¡åº¦:{test_signal['confidence']:.1%}")
        
        return True
    else:
        print("âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥")
        # æ¢å¤å¤‡ä»½
        print("ğŸ”„ æ¢å¤åŸæœ‰æ¨¡å‹...")
        for file in glob.glob(f"{backup_dir}/*"):
            filename = os.path.basename(file)
            shutil.copy2(file, f"models/{filename}")
        print("âœ… åŸæœ‰æ¨¡å‹å·²æ¢å¤")
        return False

if __name__ == "__main__":
    print("ğŸš€ AIæ¨¡å‹é‡æ–°è®­ç»ƒå·¥å…· v0.1")
    print("ä½œè€…: Alvin")
    print("="*60)
    
    # æ£€æŸ¥æ˜¯å¦ç¡®è®¤é‡æ–°è®­ç»ƒ
    response = input("âš ï¸ è¿™å°†é‡æ–°è®­ç»ƒæ¨¡å‹ä»¥æ”¯æŒ80ä¸ªç‰¹å¾ï¼Œæ˜¯å¦ç»§ç»­? (y/N): ")
    if response.lower() != 'y':
        print("âŒ å–æ¶ˆé‡æ–°è®­ç»ƒ")
        sys.exit(0)
    
    # æ‰§è¡Œé‡æ–°è®­ç»ƒ
    success = retrain_models()
    
    if success:
        print("\nğŸ‰ é‡æ–°è®­ç»ƒå®Œæˆ!")
        print("ğŸ“Š æ–°æ¨¡å‹ç‰¹ç‚¹:")
        print("- ç‰¹å¾æ•°é‡: 80ä¸ª")
        print("- é«˜æ”¶ç›Šç‰¹å¾: çªç ´ã€æœºæ„èµ„é‡‘ã€è¶…å¼ºä¿¡å·")
        print("- é¢„æœŸæå‡: å‡†ç¡®ç‡å’Œæ”¶ç›Šç‡")
        print("\nğŸ”„ è¯·é‡å¯AIæœåŠ¡ä»¥ä½¿ç”¨æ–°æ¨¡å‹:")
        print("pkill -f ai_model_service && python3 ai_model_service.py")
    else:
        print("\nâŒ é‡æ–°è®­ç»ƒå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
    
    print("="*60)
