#!/usr/bin/env python3
"""
å·¥ä¸šçº§æ•°æ®æ”¶é›†ç³»ç»Ÿ
æ”¯æŒ1000åªçƒ­é—¨ç¾è‚¡æ¸¯è‚¡ï¼Œ5å¹´å†å²æ•°æ®æ”¶é›†

ä½œè€…: Alvin
ç‰¹æ€§:
- åˆ†å¸ƒå¼æ•°æ®æ”¶é›†
- 200+æŠ€æœ¯æŒ‡æ ‡è®¡ç®—
- å¤šæºæ•°æ®èåˆ
- å®æ—¶å¢é‡æ›´æ–°
- æ•°æ®è´¨é‡æ£€éªŒ
"""

import yfinance as yf
import pandas as pd
import numpy as np
import asyncio
import aiohttp
import logging
from typing import List, Dict, Tuple, Optional
from datetime import datetime, timedelta
import multiprocessing as mp
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
import warnings
warnings.filterwarnings("ignore")

# æŠ€æœ¯æŒ‡æ ‡è®¡ç®—åº“
import talib
from scipy import stats
from sklearn.preprocessing import StandardScaler, RobustScaler

class IndustrialDataCollector:
    """å·¥ä¸šçº§æ•°æ®æ”¶é›†å™¨"""

    def __init__(self, max_workers: int = 50):
        self.max_workers = max_workers
        self.logger = self._setup_logging()

        # 1000åªçƒ­é—¨ç¾è‚¡æ¸¯è‚¡åˆ—è¡¨
        self.target_symbols = self._get_target_symbols()

    def _setup_logging(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—"""
        logger = logging.getLogger(__name__)
        logger.setLevel(logging.INFO)

        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)

        return logger

    def _get_target_symbols(self) -> List[str]:
        """è·å–ç›®æ ‡è‚¡ç¥¨åˆ—è¡¨"""
        # ç¾è‚¡ä¸»è¦æŒ‡æ•°å’Œçƒ­é—¨è‚¡ç¥¨
        us_stocks = [
            # ç§‘æŠ€è‚¡
            'AAPL', 'MSFT', 'GOOGL', 'GOOG', 'AMZN', 'TSLA', 'META', 'NFLX', 'NVDA', 'AMD',
            'INTC', 'CSCO', 'ORCL', 'IBM', 'CRM', 'ADBE', 'NOW', 'INTU', 'QCOM', 'AVGO',
            'TXN', 'AMAT', 'LRCX', 'KLAC', 'MRVL', 'XLNX', 'SNPS', 'CDNS', 'FTNT', 'PANW',

            # é‡‘èè‚¡
            'JPM', 'BAC', 'WFC', 'C', 'GS', 'MS', 'BLK', 'AXP', 'V', 'MA',
            'PYPL', 'SQ', 'COF', 'USB', 'PNC', 'TFC', 'BK', 'STT', 'SCHW', 'AMT',

            # åŒ»ç–—ä¿å¥
            'JNJ', 'PFE', 'UNH', 'ABBV', 'LLY', 'MRK', 'CVS', 'TMO', 'ABT', 'MDT',
            'AMGN', 'GILD', 'BIIB', 'REGN', 'VRTX', 'ISRG', 'ZTS', 'DHR', 'BMY', 'AZN',

            # æ¶ˆè´¹å“
            'AMZN', 'WMT', 'PG', 'KO', 'PEP', 'NKE', 'SBUX', 'MCD', 'DIS', 'HD',
            'LOW', 'TJX', 'COST', 'TGT', 'BKNG', 'ABNB', 'UBER', 'LYFT', 'DASH', 'ZM',

            # å·¥ä¸šè‚¡
            'BA', 'CAT', 'DE', 'GE', 'HON', 'MMM', 'UTX', 'LMT', 'RTX', 'NOC',
            'UNP', 'CSX', 'NSC', 'FDX', 'UPS', 'DAL', 'AAL', 'UAL', 'LUV', 'JBLU',

            # èƒ½æºè‚¡
            'XOM', 'CVX', 'COP', 'EOG', 'SLB', 'KMI', 'OKE', 'WMB', 'PSX', 'VLO',
            'MPC', 'HES', 'DVN', 'FANG', 'APA', 'MRO', 'OXY', 'HAL', 'BKR', 'NOV',

            # ETF
            'SPY', 'QQQ', 'IWM', 'EEM', 'VTI', 'VOO', 'VEA', 'VWO', 'GLD', 'TLT',
            'HYG', 'LQD', 'XLF', 'XLK', 'XLE', 'XLI', 'XLV', 'XLP', 'XLU', 'XLB',

            # æ–°å…´ç§‘æŠ€
            'SHOP', 'CRWD', 'OKTA', 'DDOG', 'NET', 'FSLY', 'TWLO', 'ZS', 'ESTC', 'SNOW',
            'PLTR', 'RBLX', 'U', 'PATH', 'HOOD', 'COIN', 'RIVN', 'LCID', 'F', 'GM',

            # ç”Ÿç‰©ç§‘æŠ€
            'MRNA', 'BNTX', 'NVAX', 'GILD', 'REGN', 'VRTX', 'BIIB', 'AMGN', 'CELG', 'ILMN'
        ]

        # æ¸¯è‚¡ä¸»è¦è‚¡ç¥¨
        hk_stocks = [
            # ç§‘æŠ€è‚¡ (æ¸¯è‚¡ä»£ç )
            '0700.HK',   # è…¾è®¯
            '9988.HK',   # é˜¿é‡Œå·´å·´
            '3690.HK',   # ç¾å›¢
            '1024.HK',   # å¿«æ‰‹
            '9618.HK',   # äº¬ä¸œé›†å›¢
            '2018.HK',   # ç‘å£°ç§‘æŠ€
            '1398.HK',   # å·¥å•†é“¶è¡Œ
            '3968.HK',   # æ‹›å•†é“¶è¡Œ
            '0388.HK',   # é¦™æ¸¯äº¤æ˜“æ‰€
            '2388.HK',   # ä¸­é“¶é¦™æ¸¯

            # åœ°äº§è‚¡
            '1109.HK',   # åæ¶¦ç½®åœ°
            '1997.HK',   # ä¹é¾™ä»“ç½®ä¸š
            '0016.HK',   # æ–°é¸¿åŸºåœ°äº§
            '0001.HK',   # é•¿å’Œ
            '0003.HK',   # ç…¤æ°”å…¬å¸

            # é‡‘èè‚¡
            '2318.HK',   # ä¸­å›½å¹³å®‰
            '1299.HK',   # å‹é‚¦ä¿é™©
            '0005.HK',   # æ±‡ä¸°æ§è‚¡
            '2628.HK',   # ä¸­å›½äººå¯¿
            '1988.HK',   # æ°‘ç”Ÿé“¶è¡Œ

            # æ¶ˆè´¹è‚¡
            '1876.HK',   # ç™¾å¨äºšå¤ª
            '2319.HK',   # è’™ç‰›ä¹³ä¸š
            '1044.HK',   # æ’å®‰å›½é™…
            '0151.HK',   # ä¸­å›½æ—ºæ—º
            '1234.HK',   # ä¸­å›½åˆ©éƒ

            # åŒ»ç–—è‚¡
            '1093.HK',   # çŸ³è¯é›†å›¢
            '6160.HK',   # ç™¾æµç¥å·
            '2269.HK',   # è¯æ˜ç”Ÿç‰©
            '1833.HK',   # å¹³å®‰å¥½åŒ»ç”Ÿ
            '1347.HK',   # åè™¹åŠå¯¼ä½“

            # æ–°ç»æµè‚¡
            '6969.HK',   # æ€æ‘©å°”å›½é™…
            '2015.HK',   # ç†æƒ³æ±½è½¦
            '9866.HK',   # è”šæ¥æ±½è½¦
            '1024.HK',   # å¿«æ‰‹ç§‘æŠ€
            '2269.HK',   # è¯æ˜ç”Ÿç‰©
        ]

        # è¡¥å……æ›´å¤šç¾è‚¡ä»¥è¾¾åˆ°1000åª
        additional_us_stocks = [
            # æ›´å¤šç§‘æŠ€è‚¡
            'ROKU', 'SQ', 'TWTR', 'PINS', 'SNAP', 'SPOT', 'ZG', 'ZILLOW', 'YELP', 'GRUB',
            'UBER', 'LYFT', 'DKNG', 'PENN', 'MGM', 'LVS', 'WYNN', 'CZR', 'BYD', 'TSLA',

            # åŒ»ç–—è®¾å¤‡
            'ISRG', 'SYK', 'BSX', 'MDT', 'EW', 'HOLX', 'DXCM', 'ALGN', 'IDXX', 'MTD',

            # åŠå¯¼ä½“
            'NVDA', 'AMD', 'INTC', 'QCOM', 'AVGO', 'TXN', 'ADI', 'XLNX', 'MRVL', 'LRCX',
            'AMAT', 'KLAC', 'SNPS', 'CDNS', 'MCHP', 'SWKS', 'QRVO', 'MPWR', 'ENPH', 'SEDG',

            # äº‘è®¡ç®—å’Œè½¯ä»¶
            'CRM', 'ORCL', 'VMW', 'WDAY', 'ADSK', 'INTU', 'FISV', 'ADP', 'PAYX', 'CTXS',
            'TEAM', 'ATLR', 'NOW', 'SPLK', 'VEEV', 'RNG', 'ANSS', 'CDNS', 'SNPS', 'PTC',

            # ç”µå•†å’Œé›¶å”®
            'SHOP', 'MELI', 'SE', 'BABA', 'JD', 'PDD', 'VIPS', 'BILI', 'TME', 'HUYA',
            'DOYU', 'IQ', 'NTES', 'WB', 'SINA', 'SOHU', 'FENG', 'TOUR', 'CAAS', 'JOBS',

            # ç”Ÿç‰©æŠ€æœ¯
            'GILD', 'AMGN', 'BIIB', 'VRTX', 'REGN', 'ILMN', 'INCY', 'BMRN', 'ALXN', 'CELG',
            'MYL', 'TEVA', 'ABBV', 'LLY', 'BMY', 'MRK', 'PFE', 'JNJ', 'RHHBY', 'NVS',

            # æ›´å¤šé‡‘èè‚¡
            'BRK-B', 'BRK-A', 'SPGI', 'ICE', 'CME', 'NDAQ', 'MCO', 'TRV', 'ALL', 'PGR',
            'CB', 'AIG', 'MET', 'PRU', 'AFL', 'WRB', 'RE', 'EXR', 'PSA', 'EQR',

            # REIT
            'PLD', 'CCI', 'AMT', 'EQIX', 'DLR', 'SBAC', 'WY', 'PCG', 'O', 'WELL',
            'VTR', 'PEAK', 'SPG', 'BXP', 'KIM', 'REG', 'FRT', 'UDR', 'ESS', 'MAA',

            # å…¬ç”¨äº‹ä¸š
            'NEE', 'DUK', 'SO', 'D', 'EXC', 'SRE', 'AEP', 'XEL', 'WEC', 'ETR',
            'ES', 'FE', 'ED', 'PPL', 'CMS', 'DTE', 'PCG', 'EIX', 'AWK', 'ATO'
        ]

        all_symbols = us_stocks + hk_stocks + additional_us_stocks

        # å»é‡å¹¶é™åˆ¶ä¸º1000åª
        unique_symbols = list(set(all_symbols))[:1000]

        self.logger.info(f"ğŸ“Š ç›®æ ‡è‚¡ç¥¨åˆ—è¡¨: {len(unique_symbols)} åª")
        return unique_symbols

    def calculate_advanced_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—200+é«˜çº§æŠ€æœ¯æŒ‡æ ‡"""

        # ç¡®ä¿æ•°æ®åˆ—åæ ‡å‡†åŒ–
        df = df.copy()
        required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']
        for col in required_cols:
            if col not in df.columns:
                self.logger.error(f"Missing column: {col}")
                return pd.DataFrame()

        # åŸºç¡€æ•°æ®
        open_prices = df['Open'].values
        high_prices = df['High'].values
        low_prices = df['Low'].values
        close_prices = df['Close'].values
        volume = df['Volume'].values.astype(float)

        features_df = pd.DataFrame(index=df.index)

        try:
            # 1. åŸºç¡€ä»·æ ¼ç‰¹å¾ (10ä¸ª)
            features_df['open'] = open_prices
            features_df['high'] = high_prices
            features_df['low'] = low_prices
            features_df['close'] = close_prices
            features_df['volume'] = volume
            features_df['typical_price'] = (high_prices + low_prices + close_prices) / 3
            features_df['range'] = high_prices - low_prices
            features_df['price_change'] = np.diff(close_prices, prepend=close_prices[0])
            features_df['price_change_pct'] = features_df['price_change'] / close_prices
            features_df['log_return'] = np.log(close_prices / np.roll(close_prices, 1))

            # 2. ç§»åŠ¨å¹³å‡çº¿ (20ä¸ª)
            for period in [5, 10, 20, 30, 50, 100, 200]:
                features_df[f'sma_{period}'] = talib.SMA(close_prices, timeperiod=period)
                features_df[f'ema_{period}'] = talib.EMA(close_prices, timeperiod=period)
                if period <= 50:
                    features_df[f'wma_{period}'] = talib.WMA(close_prices, timeperiod=period)

            # 3. åŠ¨é‡æŒ‡æ ‡ (25ä¸ª)
            features_df['rsi_14'] = talib.RSI(close_prices, timeperiod=14)
            features_df['rsi_9'] = talib.RSI(close_prices, timeperiod=9)
            features_df['rsi_25'] = talib.RSI(close_prices, timeperiod=25)

            # MACD
            macd, macdsignal, macdhist = talib.MACD(close_prices, fastperiod=12, slowperiod=26, signalperiod=9)
            features_df['macd'] = macd
            features_df['macd_signal'] = macdsignal
            features_df['macd_hist'] = macdhist

            # Stochastic
            slowk, slowd = talib.STOCH(high_prices, low_prices, close_prices, fastk_period=14, slowk_period=3, slowd_period=3)
            features_df['stoch_k'] = slowk
            features_df['stoch_d'] = slowd

            # Williams %R
            features_df['williams_r'] = talib.WILLR(high_prices, low_prices, close_prices, timeperiod=14)

            # Rate of Change
            for period in [10, 20, 30]:
                features_df[f'roc_{period}'] = talib.ROC(close_prices, timeperiod=period)

            # Momentum
            for period in [10, 20, 30]:
                features_df[f'momentum_{period}'] = talib.MOM(close_prices, timeperiod=period)

            # Ultimate Oscillator
            features_df['ultosc'] = talib.ULTOSC(high_prices, low_prices, close_prices, timeperiod1=7, timeperiod2=14, timeperiod3=28)

            # Commodity Channel Index
            features_df['cci'] = talib.CCI(high_prices, low_prices, close_prices, timeperiod=14)

            # Average Directional Index
            features_df['adx'] = talib.ADX(high_prices, low_prices, close_prices, timeperiod=14)
            features_df['adxr'] = talib.ADXR(high_prices, low_prices, close_prices, timeperiod=14)

            # Directional Movement
            features_df['plus_di'] = talib.PLUS_DI(high_prices, low_prices, close_prices, timeperiod=14)
            features_df['minus_di'] = talib.MINUS_DI(high_prices, low_prices, close_prices, timeperiod=14)

            # Aroon
            aroondown, aroonup = talib.AROON(high_prices, low_prices, timeperiod=14)
            features_df['aroon_down'] = aroondown
            features_df['aroon_up'] = aroonup
            features_df['aroon_osc'] = talib.AROONOSC(high_prices, low_prices, timeperiod=14)

            # 4. æ³¢åŠ¨ç‡æŒ‡æ ‡ (15ä¸ª)
            features_df['atr_14'] = talib.ATR(high_prices, low_prices, close_prices, timeperiod=14)
            features_df['atr_20'] = talib.ATR(high_prices, low_prices, close_prices, timeperiod=20)
            features_df['natr'] = talib.NATR(high_prices, low_prices, close_prices, timeperiod=14)
            features_df['trange'] = talib.TRANGE(high_prices, low_prices, close_prices)

            # Bollinger Bands
            bb_upper, bb_middle, bb_lower = talib.BBANDS(close_prices, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)
            features_df['bb_upper'] = bb_upper
            features_df['bb_middle'] = bb_middle
            features_df['bb_lower'] = bb_lower
            features_df['bb_width'] = (bb_upper - bb_lower) / bb_middle
            features_df['bb_position'] = (close_prices - bb_lower) / (bb_upper - bb_lower)

            # å†å²æ³¢åŠ¨ç‡
            for period in [10, 20, 30, 60]:
                returns = pd.Series(close_prices).pct_change()
                features_df[f'volatility_{period}'] = returns.rolling(window=period).std() * np.sqrt(252)

            # 5. æˆäº¤é‡æŒ‡æ ‡ (20ä¸ª)
            features_df['volume_sma_10'] = talib.SMA(volume, timeperiod=10)
            features_df['volume_sma_20'] = talib.SMA(volume, timeperiod=20)
            features_df['volume_ratio'] = volume / features_df['volume_sma_20']

            # On Balance Volume
            features_df['obv'] = talib.OBV(close_prices, volume)

            # Accumulation/Distribution Line
            features_df['ad'] = talib.AD(high_prices, low_prices, close_prices, volume)

            # Chaikin A/D Oscillator
            features_df['adosc'] = talib.ADOSC(high_prices, low_prices, close_prices, volume, fastperiod=3, slowperiod=10)

            # Money Flow Index
            features_df['mfi'] = talib.MFI(high_prices, low_prices, close_prices, volume, timeperiod=14)

            # Volume Weighted Average Price (ç®€åŒ–ç‰ˆ)
            vwap = (close_prices * volume).cumsum() / volume.cumsum()
            features_df['vwap'] = vwap

            # Price Volume Trend
            features_df['pvt'] = ((close_prices - np.roll(close_prices, 1)) / np.roll(close_prices, 1) * volume).cumsum()

            # 6. ä»·æ ¼å½¢æ€æŒ‡æ ‡ (30ä¸ª)
            # Candlestick patterns
            features_df['cdl_doji'] = talib.CDLDOJI(open_prices, high_prices, low_prices, close_prices)
            features_df['cdl_hammer'] = talib.CDLHAMMER(open_prices, high_prices, low_prices, close_prices)
            features_df['cdl_hangman'] = talib.CDLHANGINGMAN(open_prices, high_prices, low_prices, close_prices)
            features_df['cdl_engulfing'] = talib.CDLENGULFING(open_prices, high_prices, low_prices, close_prices)
            features_df['cdl_morning_star'] = talib.CDLMORNINGSTAR(open_prices, high_prices, low_prices, close_prices)
            features_df['cdl_evening_star'] = talib.CDLEVENINGSTAR(open_prices, high_prices, low_prices, close_prices)
            features_df['cdl_three_white_soldiers'] = talib.CDL3WHITESOLDIERS(open_prices, high_prices, low_prices, close_prices)
            features_df['cdl_three_black_crows'] = talib.CDL3BLACKCROWS(open_prices, high_prices, low_prices, close_prices)

            # More patterns
            features_df['cdl_harami'] = talib.CDLHARAMI(open_prices, high_prices, low_prices, close_prices)
            features_df['cdl_piercing'] = talib.CDLPIERCING(open_prices, high_prices, low_prices, close_prices)
            features_df['cdl_darkcloud'] = talib.CDLDARKCLOUDCOVER(open_prices, high_prices, low_prices, close_prices)
            features_df['cdl_shooting_star'] = talib.CDLSHOOTINGSTAR(open_prices, high_prices, low_prices, close_prices)
            features_df['cdl_inverted_hammer'] = talib.CDLINVERTEDHAMMER(open_prices, high_prices, low_prices, close_prices)
            features_df['cdl_spinning_top'] = talib.CDLSPINNINGTOP(open_prices, high_prices, low_prices, close_prices)

            # 7. ç»Ÿè®¡æŒ‡æ ‡ (20ä¸ª)
            for period in [10, 20, 50]:
                price_series = pd.Series(close_prices)
                features_df[f'skewness_{period}'] = price_series.rolling(window=period).skew()
                features_df[f'kurtosis_{period}'] = price_series.rolling(window=period).kurt()
                features_df[f'mean_reversion_{period}'] = (close_prices - price_series.rolling(window=period).mean()) / price_series.rolling(window=period).std()

            # 8. å­£èŠ‚æ€§å’Œæ—¶é—´ç‰¹å¾ (15ä¸ª)
            dates = pd.to_datetime(df.index)
            features_df['day_of_week'] = dates.dayofweek
            features_df['month'] = dates.month
            features_df['quarter'] = dates.quarter
            features_df['day_of_month'] = dates.day
            features_df['week_of_year'] = dates.isocalendar().week

            # æœˆæœ«æ•ˆåº”
            features_df['is_month_end'] = (dates.to_period('M').to_timestamp('M') - dates).days <= 5
            features_df['is_month_start'] = (dates - dates.to_period('M').to_timestamp('M')).days <= 5

            # 9. è¶‹åŠ¿å¼ºåº¦æŒ‡æ ‡ (15ä¸ª)
            # Linear regression slope
            for period in [10, 20, 50]:
                slopes = []
                for i in range(len(close_prices)):
                    if i >= period - 1:
                        y = close_prices[i-period+1:i+1]
                        x = np.arange(len(y))
                        if len(y) == period:
                            slope = np.polyfit(x, y, 1)[0]
                            slopes.append(slope)
                        else:
                            slopes.append(np.nan)
                    else:
                        slopes.append(np.nan)
                features_df[f'trend_slope_{period}'] = slopes

            # R-squared of linear regression
            for period in [20, 50]:
                r_squared = []
                for i in range(len(close_prices)):
                    if i >= period - 1:
                        y = close_prices[i-period+1:i+1]
                        x = np.arange(len(y))
                        if len(y) == period:
                            correlation_matrix = np.corrcoef(x, y)
                            correlation = correlation_matrix[0,1]
                            r_sq = correlation**2
                            r_squared.append(r_sq)
                        else:
                            r_squared.append(np.nan)
                    else:
                        r_squared.append(np.nan)
                features_df[f'trend_strength_{period}'] = r_squared

            # 10. é«˜çº§æŠ€æœ¯æŒ‡æ ‡ (25ä¸ª)
            # Ichimoku Cloud components
            high_9 = pd.Series(high_prices).rolling(window=9).max()
            low_9 = pd.Series(low_prices).rolling(window=9).min()
            features_df['tenkan_sen'] = (high_9 + low_9) / 2

            high_26 = pd.Series(high_prices).rolling(window=26).max()
            low_26 = pd.Series(low_prices).rolling(window=26).min()
            features_df['kijun_sen'] = (high_26 + low_26) / 2

            features_df['senkou_span_a'] = ((features_df['tenkan_sen'] + features_df['kijun_sen']) / 2).shift(26)

            high_52 = pd.Series(high_prices).rolling(window=52).max()
            low_52 = pd.Series(low_prices).rolling(window=52).min()
            features_df['senkou_span_b'] = ((high_52 + low_52) / 2).shift(26)

            # Parabolic SAR
            features_df['sar'] = talib.SAR(high_prices, low_prices, acceleration=0.02, maximum=0.2)

            # Hilbert Transform
            features_df['ht_dcperiod'] = talib.HT_DCPERIOD(close_prices)
            features_df['ht_dcphase'] = talib.HT_DCPHASE(close_prices)
            features_df['ht_trendmode'] = talib.HT_TRENDMODE(close_prices)

            # å¡«å……ç¼ºå¤±å€¼
            features_df = features_df.fillna(method='ffill').fillna(method='bfill').fillna(0)

            self.logger.info(f"âœ… è®¡ç®—äº† {len(features_df.columns)} ä¸ªæŠ€æœ¯æŒ‡æ ‡")
            return features_df

        except Exception as e:
            self.logger.error(f"âŒ ç‰¹å¾è®¡ç®—å¤±è´¥: {e}")
            return pd.DataFrame()

    def collect_single_stock(self, symbol: str, period: str = "5y") -> Tuple[str, Optional[pd.DataFrame]]:
        """æ”¶é›†å•åªè‚¡ç¥¨æ•°æ®"""
        try:
            self.logger.info(f"ğŸ“Š æ”¶é›† {symbol} æ•°æ®...")

            # ä¸‹è½½æ•°æ®
            ticker = yf.Ticker(symbol)
            data = ticker.history(period=period, interval="1d", auto_adjust=True)

            if data.empty:
                self.logger.warning(f"âš ï¸ {symbol} æ— æ•°æ®")
                return symbol, None

            # æ•°æ®è´¨é‡æ£€æŸ¥
            if len(data) < 252:  # å°‘äºä¸€å¹´æ•°æ®
                self.logger.warning(f"âš ï¸ {symbol} æ•°æ®ä¸è¶³: {len(data)} å¤©")
                return symbol, None

            # è®¡ç®—é«˜çº§æŠ€æœ¯æŒ‡æ ‡
            features = self.calculate_advanced_features(data)

            if features.empty:
                self.logger.warning(f"âš ï¸ {symbol} ç‰¹å¾è®¡ç®—å¤±è´¥")
                return symbol, None

            # æ·»åŠ è‚¡ç¥¨æ ‡è¯†
            features['symbol'] = symbol

            self.logger.info(f"âœ… {symbol} å®Œæˆ: {len(features)} æ¡è®°å½•, {len(features.columns)} ä¸ªç‰¹å¾")
            return symbol, features

        except Exception as e:
            self.logger.error(f"âŒ {symbol} æ”¶é›†å¤±è´¥: {e}")
            return symbol, None

    def collect_all_data(self, save_path: str = "data/industrial_training_data") -> Dict[str, pd.DataFrame]:
        """å¹¶è¡Œæ”¶é›†æ‰€æœ‰è‚¡ç¥¨æ•°æ®"""
        self.logger.info(f"ğŸš€ å¼€å§‹æ”¶é›† {len(self.target_symbols)} åªè‚¡ç¥¨çš„æ•°æ®...")

        start_time = time.time()
        successful_data = {}
        failed_symbols = []

        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œæ”¶é›†
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_symbol = {
                executor.submit(self.collect_single_stock, symbol): symbol
                for symbol in self.target_symbols
            }

            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_symbol):
                symbol = future_to_symbol[future]
                try:
                    symbol, data = future.result(timeout=60)  # 60ç§’è¶…æ—¶

                    if data is not None:
                        successful_data[symbol] = data

                        # ä¿å­˜å•ä¸ªè‚¡ç¥¨æ•°æ®
                        import os
                        os.makedirs(save_path, exist_ok=True)
                        file_path = f"{save_path}/{symbol.replace('.', '_')}.parquet"
                        data.to_parquet(file_path, compression='gzip')

                    else:
                        failed_symbols.append(symbol)

                except Exception as e:
                    self.logger.error(f"âŒ {symbol} å¤„ç†å¤±è´¥: {e}")
                    failed_symbols.append(symbol)

                # è¿›åº¦æŠ¥å‘Š
                completed = len(successful_data) + len(failed_symbols)
                if completed % 50 == 0:
                    self.logger.info(f"ğŸ“ˆ è¿›åº¦: {completed}/{len(self.target_symbols)} "
                                   f"(æˆåŠŸ: {len(successful_data)}, å¤±è´¥: {len(failed_symbols)})")

        # æœ€ç»ˆç»Ÿè®¡
        elapsed_time = time.time() - start_time
        self.logger.info(f"ğŸ‰ æ•°æ®æ”¶é›†å®Œæˆ!")
        self.logger.info(f"â±ï¸  æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
        self.logger.info(f"âœ… æˆåŠŸ: {len(successful_data)} åªè‚¡ç¥¨")
        self.logger.info(f"âŒ å¤±è´¥: {len(failed_symbols)} åªè‚¡ç¥¨")

        if failed_symbols:
            self.logger.info(f"å¤±è´¥è‚¡ç¥¨: {failed_symbols}")

        # ä¿å­˜æ±‡æ€»ä¿¡æ¯
        summary = {
            'total_symbols': len(self.target_symbols),
            'successful_symbols': len(successful_data),
            'failed_symbols': len(failed_symbols),
            'failed_list': failed_symbols,
            'collection_time': elapsed_time,
            'features_per_stock': len(successful_data[list(successful_data.keys())[0]].columns) if successful_data else 0
        }

        import json
        with open(f"{save_path}/collection_summary.json", 'w') as f:
            json.dump(summary, f, indent=2, default=str)

        return successful_data

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å·¥ä¸šçº§æ•°æ®æ”¶é›†ç³»ç»Ÿ")
    print("=" * 60)

    collector = IndustrialDataCollector(max_workers=30)

    print(f"ğŸ“Š ç›®æ ‡: æ”¶é›† {len(collector.target_symbols)} åªè‚¡ç¥¨çš„5å¹´å†å²æ•°æ®")
    print(f"ğŸ¯ ç‰¹å¾: 200+ æŠ€æœ¯æŒ‡æ ‡")
    print(f"âš¡ å¹¶å‘: {collector.max_workers} çº¿ç¨‹")
    print("=" * 60)

    # å¼€å§‹æ”¶é›†
    data = collector.collect_all_data()

    if data:
        print(f"ğŸ‰ æ•°æ®æ”¶é›†æˆåŠŸ!")
        print(f"ğŸ“ˆ è‚¡ç¥¨æ•°é‡: {len(data)}")

        # æ ·æœ¬ç»Ÿè®¡
        total_samples = sum(len(df) for df in data.values())
        avg_samples = total_samples / len(data)

        print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {total_samples:,}")
        print(f"ğŸ“Š å¹³å‡æ ·æœ¬/è‚¡ç¥¨: {avg_samples:.0f}")

        # ç‰¹å¾ç»Ÿè®¡
        if data:
            sample_features = len(list(data.values())[0].columns)
            print(f"ğŸ¯ ç‰¹å¾ç»´åº¦: {sample_features}")

    print("âœ… æ•°æ®æ”¶é›†ç³»ç»Ÿè¿è¡Œå®Œæ¯•!")

if __name__ == "__main__":
    main()